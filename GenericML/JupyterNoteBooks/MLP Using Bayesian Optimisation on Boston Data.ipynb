{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP Using Bayesian Optimisation on Boston Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.gaussian_process as gp\n",
    "\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "\n",
    "def optimize(n_iters, loss_func, bounds, stop_func, x0=None, n_pre_samples=5,\n",
    "                          gp_params=None, random_search=False, alpha=1e-5, epsilon=1e-7,):\n",
    "\n",
    "    x_list = []\n",
    "    y_list = []\n",
    "\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    if x0 is None:\n",
    "        for params in np.random.uniform(bounds[:, 0], bounds[:, 1], (n_pre_samples, bounds.shape[0])):\n",
    "            x_list.append(params)\n",
    "            y_list.append(loss_func(params))\n",
    "    else:\n",
    "        for params in x0:\n",
    "            x_list.append(params)\n",
    "            y_list.append(loss_func(params))\n",
    "\n",
    "    xp = np.array(x_list)\n",
    "    yp = np.array(y_list)\n",
    "\n",
    "    # Create the GP\n",
    "    if gp_params is not None:\n",
    "        model = gp.GaussianProcessRegressor(**gp_params)\n",
    "    else:\n",
    "        kernel = gp.kernels.Matern()\n",
    "        model = gp.GaussianProcessRegressor(kernel=kernel,\n",
    "                                            alpha=alpha,\n",
    "                                            n_restarts_optimizer=10,\n",
    "                                            normalize_y=True)\n",
    "\n",
    "    for _ in range(n_iters):\n",
    "\n",
    "        model.fit(xp, yp)\n",
    "\n",
    "        # Sample next hyperparameter\n",
    "        if random_search:\n",
    "            x_random = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(random_search, n_params))\n",
    "            ei = -1 * expected_improvement(x_random, model, yp, greater_is_better=True, n_params=n_params)\n",
    "            next_sample = x_random[np.argmax(ei), :]\n",
    "        else:\n",
    "            next_sample = sample_next_hyperparameter(expected_improvement, model, yp, greater_is_better=True, bounds=bounds, n_restarts=100)\n",
    "\n",
    "        # Duplicates will break the GP. In case of a duplicate, we will randomly sample a next query point.\n",
    "        if np.any(np.abs(next_sample - xp) <= epsilon):\n",
    "            next_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], bounds.shape[0])\n",
    "\n",
    "        # Sample loss for new set of parameters\n",
    "        cv_score = loss_func(next_sample)\n",
    "\n",
    "        # Update lists\n",
    "        x_list.append(next_sample)\n",
    "        y_list.append(cv_score)\n",
    "\n",
    "        # Update xp and yp\n",
    "        xp = np.array(x_list)\n",
    "        yp = np.array(y_list)\n",
    "        if stop_func(yp):\n",
    "            print('Iteration stopped prematurely, reason: stop criteria met')\n",
    "            return xp, yp\n",
    "\n",
    "    return xp, yp\n",
    "\n",
    "\n",
    "def sample_next_hyperparameter(acquisition_func, gaussian_process, evaluated_loss, greater_is_better=False,\n",
    "                               bounds=(0, 10), n_restarts=25):\n",
    "\n",
    "    best_x = None\n",
    "    best_acquisition_value = 1\n",
    "    n_params = bounds.shape[0]\n",
    "\n",
    "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, n_params)):\n",
    "\n",
    "        res = minimize(fun=acquisition_func,\n",
    "                       x0=starting_point.reshape(1, -1),\n",
    "                       bounds=bounds,\n",
    "                       method='L-BFGS-B',\n",
    "                       args=(gaussian_process, evaluated_loss, greater_is_better, n_params))\n",
    "\n",
    "        if res.fun < best_acquisition_value:\n",
    "            best_acquisition_value = res.fun\n",
    "            best_x = res.x\n",
    "\n",
    "    return best_x\n",
    "\n",
    "\n",
    "def expected_improvement(x, gaussian_process, evaluated_loss, greater_is_better=False, n_params=1):\n",
    "\n",
    "    x_to_predict = x.reshape(-1, n_params)\n",
    "\n",
    "    mu, sigma = gaussian_process.predict(x_to_predict, return_std=True)\n",
    "\n",
    "    if greater_is_better:\n",
    "        loss_optimum = np.max(evaluated_loss)\n",
    "    else:\n",
    "        loss_optimum = np.min(evaluated_loss)\n",
    "\n",
    "    scaling_factor = (-1) ** (not greater_is_better)\n",
    "\n",
    "    # In case sigma equals zero\n",
    "    with np.errstate(divide='ignore'):\n",
    "        Z = scaling_factor * (mu - loss_optimum) / sigma\n",
    "        expected_improvement = scaling_factor * (mu - loss_optimum) * norm.cdf(Z) + sigma * norm.pdf(Z)\n",
    "\n",
    "    return -1 * expected_improvement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected parameters are  [8.55133310e+00 1.49231764e-04]\n",
      "Value at selected parameters is,  -19.26565312196637\n",
      "Selected parameters are  [1.00001674e+00 5.31975304e-04]\n",
      "Value at selected parameters is,  -25.106899800611362\n",
      "Selected parameters are  [8.55145623e+00 1.75039894e-04]\n",
      "Value at selected parameters is,  -18.235125257519584\n",
      "Selected parameters are  [8.55123650e+00 2.52383858e-04]\n",
      "Value at selected parameters is,  -22.307842501789306\n",
      "Selected parameters are  [8.55170575e+00 2.48133357e-04]\n",
      "Value at selected parameters is,  -24.20231379903165\n",
      "Selected parameters are  [9.36297888e+00 4.99723643e-04]\n",
      "Value at selected parameters is,  -23.302270133507513\n",
      "Selected parameters are  [8.55151466e+00 2.71168415e-04]\n",
      "Value at selected parameters is,  -20.696173491992802\n",
      "Selected parameters are  [8.55136162e+00 1.16220516e-04]\n",
      "Value at selected parameters is,  -19.425200035307885\n",
      "Selected parameters are  [8.55130110e+00 1.27322125e-04]\n",
      "Value at selected parameters is,  -19.082663131163862\n",
      "Selected parameters are  [8.95901004e+00 3.99296960e-04]\n",
      "Value at selected parameters is,  -21.37609593831427\n",
      "Selected parameters are  [9.16863286e+00 1.00811869e-04]\n",
      "Value at selected parameters is,  -18.68125061136272\n",
      "Selected parameters are  [8.55154037e+00 1.58583442e-04]\n",
      "Value at selected parameters is,  -26.331175167086464\n",
      "Selected parameters are  [8.55144098e+00 1.26329349e-04]\n",
      "Value at selected parameters is,  -20.356307838172462\n",
      "Selected parameters are  [8.55137453e+00 3.69770353e-04]\n",
      "Value at selected parameters is,  -20.970934166864204\n",
      "Selected parameters are  [8.55133847e+00 1.37709705e-04]\n",
      "Value at selected parameters is,  -15.727787612511019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puru_\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.13856519e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 52, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n",
      "C:\\Users\\puru_\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([-2.05891063e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 53, 'nit': 7, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected parameters are  [8.55147694e+00 2.36050184e-04]\n",
      "Value at selected parameters is,  -18.86164576020468\n",
      "Selected parameters are  [9.16869042e+00 1.29747920e-04]\n",
      "Value at selected parameters is,  -19.93550731826675\n",
      "Selected parameters are  [9.16876453e+00 1.37497028e-04]\n",
      "Value at selected parameters is,  -19.310542572200735\n",
      "Selected parameters are  [8.55144234e+00 2.76057177e-04]\n",
      "Value at selected parameters is,  -16.07306117736503\n",
      "Selected parameters are  [8.55145148e+00 2.60069819e-04]\n",
      "Value at selected parameters is,  -16.87632942022315\n",
      "Selected parameters are  [9.16840390e+00 1.71863598e-04]\n",
      "Value at selected parameters is,  -17.154245677610717\n",
      "Selected parameters are  [8.55130608e+00 1.03125305e-04]\n",
      "Value at selected parameters is,  -25.20720805317157\n",
      "Selected parameters are  [9.16840659e+00 2.15359230e-04]\n",
      "Value at selected parameters is,  -21.36169843958185\n",
      "Selected parameters are  [9.16878604e+00 1.71309946e-04]\n",
      "Value at selected parameters is,  -16.725080340524112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puru_\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([3.29298384e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected parameters are  [9.16873493e+00 1.52758986e-04]\n",
      "Value at selected parameters is,  -19.636482737133612\n",
      "Selected parameters are  [9.16883393e+00 2.25845001e-04]\n",
      "Value at selected parameters is,  -19.83480389020182\n",
      "Selected parameters are  [9.16860977e+00 1.33580145e-04]\n",
      "Value at selected parameters is,  -21.774598647887395\n",
      "Selected parameters are  [5.99396542e+00 6.12833789e-04]\n",
      "Value at selected parameters is,  -17.938086437230318\n",
      "Selected parameters are  [9.16869390e+00 3.56928579e-04]\n",
      "Value at selected parameters is,  -23.35762534432762\n",
      "Selected parameters are  [5.99414784e+00 6.39350930e-04]\n",
      "Value at selected parameters is,  -23.20460376112054\n",
      "Selected parameters are  [9.16881024e+00 2.89852717e-04]\n",
      "Value at selected parameters is,  -21.26304192562522\n",
      "Selected parameters are  [8.55141919e+00 1.96342497e-04]\n",
      "Value at selected parameters is,  -21.473523131813636\n",
      "Selected parameters are  [8.55128678e+00 1.34245535e-04]\n",
      "Value at selected parameters is,  -22.140851223735762\n",
      "Selected parameters are  [5.99391040e+00 6.63388288e-04]\n",
      "Value at selected parameters is,  -17.904374139386885\n",
      "Selected parameters are  [5.99379849e+00 8.43653652e-04]\n",
      "Value at selected parameters is,  -20.225131854494787\n",
      "Selected parameters are  [5.99390542e+00 5.52068081e-04]\n",
      "Value at selected parameters is,  -18.894524886751743\n",
      "Selected parameters are  [5.99397554e+00 6.55076289e-04]\n",
      "Value at selected parameters is,  -16.34402776560152\n",
      "Selected parameters are  [5.99394047e+00 5.21881664e-04]\n",
      "Value at selected parameters is,  -20.706753423124603\n",
      "Selected parameters are  [5.99389557e+00 6.31492495e-04]\n",
      "Value at selected parameters is,  -17.294750936214673\n",
      "Selected parameters are  [9.16838372e+00 1.22246902e-04]\n",
      "Value at selected parameters is,  -28.357896129936783\n",
      "Selected parameters are  [5.99391608e+00 6.02595618e-04]\n",
      "Value at selected parameters is,  -17.629615442953458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\puru_\\Anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\gpr.py:457: UserWarning: fmin_l_bfgs_b terminated abnormally with the  state: {'grad': array([6.14225725e-05]), 'task': b'ABNORMAL_TERMINATION_IN_LNSRCH', 'funcalls': 50, 'nit': 6, 'warnflag': 2}\n",
      "  \" state: %s\" % convergence_dict)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected parameters are  [8.55147835e+00 2.19439084e-04]\n",
      "Value at selected parameters is,  -19.42554114308679\n",
      "Selected parameters are  [9.16866627e+00 1.72650931e-04]\n",
      "Value at selected parameters is,  -19.2489504239401\n",
      "Selected parameters are  [5.99401038e+00 6.46334370e-04]\n",
      "Value at selected parameters is,  -16.14856967478893\n",
      "Selected parameters are  [5.99394059e+00 6.36585131e-04]\n",
      "Value at selected parameters is,  -19.550524903163186\n",
      "Selected parameters are  [7.67170124e+00 4.19680885e-04]\n",
      "Value at selected parameters is,  -16.42926481615205\n",
      "Selected parameters are  [9.16885817e+00 2.53842214e-04]\n",
      "Value at selected parameters is,  -18.026398477026316\n",
      "Selected parameters are  [5.99392257e+00 6.44792723e-04]\n",
      "Value at selected parameters is,  -22.836992720053974\n",
      "Selected parameters are  [9.16886094e+00 2.64102617e-04]\n",
      "Value at selected parameters is,  -20.466870719122728\n",
      "Selected parameters are  [9.16844955e+00 1.90140521e-04]\n",
      "Value at selected parameters is,  -23.53902342415849\n",
      "Selected parameters are  [5.99391578e+00 7.36023822e-04]\n",
      "Value at selected parameters is,  -23.344472904090555\n",
      "Best score found is  -15.727787612511019\n",
      "Best settings are found is  [8.55133847e+00 1.37709705e-04]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "\n",
    "def loss_func(params):\n",
    "    \n",
    "    val = cross_val_score(MLPRegressor(hidden_layer_sizes=(int(np.round(params[0]))), activation='relu', alpha=params[1], batch_size='auto', solver='lbfgs', max_iter=600),\n",
    "                         X=X_train, y=y_train, scoring='neg_mean_squared_error', cv=5).mean()\n",
    "                    \n",
    "    print(\"Selected parameters are \", params)\n",
    "    print(\"Value at selected parameters is, \", val)\n",
    "    return val\n",
    "\n",
    "\n",
    "def stop_func(y):\n",
    "    if len(y) <= 10:\n",
    "        return False\n",
    "    y = y[-10:]\n",
    "    max_val = np.max(y)\n",
    "    min_val = np.min(y)\n",
    "    # Can change the value here for other stop criteria\n",
    "    if abs(max_val - min_val) < 1e-4:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "boston = load_boston()\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "bounds = np.array([[1, 10], [0.0001, 0.001]])\n",
    "\n",
    "xp, yp = optimize(n_iters=50,\n",
    "                            loss_func=loss_func,\n",
    "                            bounds=bounds,\n",
    "                            stop_func=stop_func,\n",
    "                            n_pre_samples=1,\n",
    "                            random_search=100000)\n",
    "indx = np.argmax(yp)\n",
    "print('Best score found is ', yp[indx])\n",
    "print('Best settings are found is ', xp[indx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train MSE: 3.59\n",
      "Test MSE: 10.9\n"
     ]
    }
   ],
   "source": [
    "mlp = MLPRegressor(hidden_layer_sizes=(int(np.round(xp[indx][0]))), activation='relu', alpha=xp[indx][1], batch_size='auto', solver='lbfgs', max_iter=600)\n",
    "mlp.fit(X_train, y_train)\n",
    "train_mse = mean_squared_error(y_train, mlp.predict(X_train))\n",
    "test_mse = mean_squared_error(y_test, mlp.predict(X_test))\n",
    " \n",
    "print(\"Train MSE:\", np.round(train_mse, 2))\n",
    "print(\"Test MSE:\", np.round(test_mse, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~puru_cr7/9.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "trace = go.Scatter(\n",
    "    x = y_test,\n",
    "    y = mlp.predict(X_test),\n",
    "    mode = 'markers',\n",
    "    name=\"Predicted vs Actual\"\n",
    ")\n",
    "trace1 = go.Scatter(\n",
    "    name=\"Best Fit\",\n",
    "    x = y_test,\n",
    "    y = y_test,\n",
    "    line = dict(\n",
    "        color = ('rgb(0, 0, 0)'),\n",
    "        width = 4,\n",
    "        dash = 'dash')\n",
    ")\n",
    "data1 = [trace,trace1]\n",
    "\n",
    "# Plot and embed in ipython notebook!\n",
    "py.iplot(data1, filename='basic-scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
